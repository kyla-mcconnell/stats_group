<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Kyla McConnell" />


<title>Inferential Statistics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Stats Group</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="calendar.html">Schedule</a>
</li>
<li>
  <a href="bytopic.html">Notes &amp; Exercises</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Inferential Statistics</h1>
<h4 class="author">Kyla McConnell</h4>
<h4 class="date">8/27/2020</h4>

</div>


<p>Based on Chapters 9 - 11 of <a href="https://www.amazon.de/Statistics-Linguists-Introduction-Using-R/dp/113805609X/ref=sxts_sxwds-bia-wc-drs1_0?cv_ct_cx=Statistics+for+Linguists%3A+An+Introduction+Using+R&amp;dchild=1&amp;keywords=Statistics+for+Linguists%3A+An+Introduction+Using+R&amp;pd_rd_i=113805609X&amp;pd_rd_r=ad49314f-6c56-4dfd-af51-df73083c56ff&amp;pd_rd_w=FT3O0&amp;pd_rd_wg=1F20M&amp;pf_rd_p=4550c966-ade8-45b3-8233-8740fa4921e3&amp;pf_rd_r=KHZ507X5ZP0TFNMBMRTJ&amp;psc=1&amp;qid=1598614090&amp;sr=1-1-95fb4f3c-fa15-48dc-bab1-67b29ab0ca13">Winter 2020 - Statistics for Linguists</a>.</p>
<div id="inferential-statistics-in-a-regression-context" class="section level1">
<h1>Inferential statistics in a regression context</h1>
<div id="effect-size" class="section level2">
<h2>Effect size</h2>
<div id="cohens-d" class="section level3">
<h3>Cohen’s d</h3>
<p>d = x̅ 1- x̅ 2?/s</p>
<p>Mean of group 1 minus mean of group 2 divided by standard deviation.</p>
<p>Considers the magnitude of the effect (difference in means) and the variability in the data (standard deviation). Grows if the standard deviation is bigger or if the difference in means is bigger</p>
<p>Measure of effect size</p>
<p>d = |.02| -&gt; small effect d = |.05| -&gt; medium effect d = |.08| -&gt; large effect</p>
</div>
<div id="pearsons-r" class="section level3">
<h3>Pearson’s r</h3>
<p>r = s^2x,y / sx sy</p>
<p>Covariance divided by standard deviations of both groups multiplied together.</p>
<p>Covariance measures the x-distance of each data point from the x-mean and the y-distance of each data point from the y-mean. If a point is much above or much below both, the number grows (or vice versa).</p>
<p>Measure of correlation and/or effect size</p>
</div>
</div>
<div id="standard-errors-and-confidence-intervals" class="section level2">
<h2>Standard errors and confidence intervals</h2>
<div id="standard-error" class="section level3">
<h3>Standard error</h3>
<p>SE = s/root(N)</p>
<p>Considers variability in the data (standard deviation) and sample size (root(N)).</p>
<p>Differs to standard deviation because it considers the sample size. Thus it is is the population-level estimate/equivalent of the sample-level standard error.</p>
</div>
<div id="confidence-interval" class="section level3">
<h3>Confidence interval</h3>
<p>Confidence intervals show 1.96 standard errors above and below the mean. 1.96 is derived from the 0.05 significance level standard in frequentist statistics.</p>
<p>CI = [x̅ - 1.96 * SE, x̅ + 1.96 * SE]</p>
<p>Confidence intervals will include the true population mean 95% of the time.</p>
</div>
</div>
<div id="significance" class="section level2">
<h2>Significance</h2>
<div id="null-hypothesis" class="section level3">
<h3>Null hypothesis</h3>
<p>Null hypothesis, H0: mu1 = mu2 i.e. Mean of group one = mean of group two, there is no difference between groups (on the population level, which is why we use mu, not x-bar)</p>
<p>The null hypothesis cannot be found true or false. What you measure is the current data’s incompatibility with the null hypothesis.</p>
<p>If you find evidence for the null hypothesis, this does not mean that there is no effect (especially, for example, your sample size is small)</p>
</div>
<div id="t-statistic" class="section level3">
<h3>t-statistic</h3>
<p>t = x̅1 - x̅2 / SE</p>
<p>Difference in group means divided by the standard error.</p>
<p>The standard error considers the sample size (unlike the standard deviation used in Cohen’s d).</p>
<p>Considers magnitude of the effect (numerator grows if the difference in group means grows), the variability in the data (numerator of the SE) and the effect size (denominators of the SE).</p>
<p>t-statistics can be used to compute p-values. The t-distribution is similar to the normal distribution, just with thicker tails. A 0.05 significance level computes to about t = |1.98|</p>
</div>
<div id="p-values" class="section level3">
<h3>p-values</h3>
<p>p-values do not measure the likelihood of the null hypothesis being true or the strength of an effect.</p>
</div>
<div id="type-i-and-type-ii-error" class="section level3">
<h3>Type I and Type II error</h3>
<p>Type I error: getting a significant effect although the null hypothesis is true at the population level – false positive Alpha (α) = the probability of a type I error over the long run / our willingness to accept a type I error</p>
<p>Type II error: failing to get a significant effect although the null hypothesis is not true at the population level – false negative Beta (β) = the probability of a type II error over the long run / our willingness to accept a type II error</p>
<p>Statistical power = 1 - beta (sometimes represented by the pi symbol) Power is increased by having a large sample size, decreasing variability in the data (smaller s), or increasing the effect size.</p>
<p>Type M error: error in estimating the magnitude of an effect (i.e. much larger than it really is), often caused by small sample sizes Type S error: “failure to capture the correct sign of an effect”, often caused by small sample sizes</p>
</div>
</div>
<div id="multiple-testing" class="section level2">
<h2>Multiple testing</h2>
<p>The more tests you carry out, the more likely you are to commit a Type I error (they all have positive chances, and these add up).</p>
<p>Family-wise error rate: likelihood of conducting a Type I error over multiple tests</p>
<p>FWER = 1 - (1 - 0.05)^k where k is the number of tests.</p>
<p>If you conduct 20 tests, the family-wise error rate quickly shoots up to 64%.</p>
<p>Bonferonni correction: Divide the alpha level by the number of tests. If it is confusing to the audience to see very small p-values that are not treated as significant, you can also adjust the p-values themselves:</p>
<pre class="r"><code>p.adjust(0.03, method=&quot;bonferroni&quot;, n=2)</code></pre>
<pre><code>## [1] 0.06</code></pre>
<div id="stopping-rules" class="section level3">
<h3>Stopping rules</h3>
<p>If the null hypothesis is true, p-values are uniformly distributed from 0 to 1, so any p-value is equally as likely as any other.</p>
<p>#Application to modeling</p>
<pre class="r"><code>library(tidyverse)
library(broom)

icon &lt;- read_csv(&quot;data/perry_winter_2017_iconicity.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   Word = col_character(),
##   POS = col_character(),
##   SER = col_double(),
##   CorteseImag = col_double(),
##   Conc = col_double(),
##   Syst = col_double(),
##   Freq = col_double(),
##   Iconicity = col_double()
## )</code></pre>
<pre class="r"><code>icon &lt;- icon %&gt;% 
  mutate(SER_z = scale(SER),
         CorteseImag_z =  scale(CorteseImag),
         Syst_z = scale(Syst),
         Freq_z = scale(Freq))

icon_mdl_z &lt;- lm(Iconicity ~ SER_z + CorteseImag_z + Syst_z + Freq_z , data = icon)

tidy(icon_mdl_z) %&gt;% 
  mutate(p.value = format.pval(p.value, 4),
         estimate = round(estimate, 2),
         std.error = round(std.error, 2),
         statistic = round(statistic, 2))</code></pre>
<pre><code>## # A tibble: 5 x 5
##   term          estimate std.error statistic p.value
##   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  
## 1 (Intercept)       1.15      0.03     33.3  4      
## 2 SER_z             0.53      0.04     12.5  4      
## 3 CorteseImag_z    -0.42      0.04    -10.7  4      
## 4 Syst_z            0.06      0.03      1.79 4      
## 5 Freq_z           -0.36      0.11     -3.2  4</code></pre>
<p>Remember what the p-value means: how likely/expected it is that you would find a slope as or more extreme if the true population slope was 0.</p>
<p>Suggestion on how to write up: “SER was positively associated with iconicity (+0.53, SE = 0.04, p &lt; 0.001)” and “for each inncnrease inn nsensory experience rating by one standard deviation, iconicity ratings increased by 0.52 (b = 0.53, SE = 0.04, p &lt; 0.001)”.</p>
</div>
<div id="dot-and-whisker-plot" class="section level3">
<h3>Dot and whisker plot</h3>
<pre class="r"><code>mycoefs &lt;- tidy(icon_mdl_z, conf.int = TRUE) %&gt;%  #conf.int incluseds 95% conf. intervals  in output
  filter(term != &quot;(Intercept)&quot;) 

pred_order &lt;- arrange(mycoefs, estimate)$term

mycoefs &lt;- mycoefs %&gt;% 
  mutate(term = factor(term, levels = pred_order))
  
ggplot(aes(x = term, y = estimate), data = mycoefs) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  geom_hline(yintercept = 0, linetype = 2) +
  coord_flip() +
  theme_minimal()</code></pre>
<p><img src="inferential_stats_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="multilevel-categorical-predictors" class="section level3">
<h3>Multilevel categorical predictors</h3>
<pre class="r"><code>senses &lt;- read_csv(&quot;data/winter_2016_senses_valence.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   Word = col_character(),
##   Modality = col_character(),
##   Val = col_double()
## )</code></pre>
<pre class="r"><code>senses_mdl &lt;- lm(Val ~ Modality, data = senses)

tidy(senses_mdl) %&gt;% 
  mutate(estimate = round(estimate, 2), 
         std.error = round(std.error, 2),
         statistics = round(statistic, 2),
         p.value = format.pval(p.value, 4))</code></pre>
<pre><code>## # A tibble: 5 x 6
##   term          estimate std.error statistic p.value statistics
##   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;
## 1 (Intercept)       5.58      0.02    295.   4           295.  
## 2 ModalitySmell    -0.11      0.06     -1.93 4            -1.93
## 3 ModalitySound    -0.17      0.04     -4.64 4            -4.64
## 4 ModalityTaste     0.23      0.04      5.30 4             5.3 
## 5 ModalityTouch    -0.05      0.04     -1.21 4            -1.21</code></pre>
<p>Reference level: Sight Thus, p-values reflect H0 that the difference between Sight and the given level is 0. Thus, we are missing a lot of info here.</p>
<p>Compare to null model:</p>
<pre class="r"><code>senses_null &lt;- lm(Val ~ 1, data = senses) #1 is a placeholder for intercept only

anova(senses_null, senses_mdl)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Val ~ 1
## Model 2: Val ~ Modality
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    404 33.089                                  
## 2    400 28.274  4    4.8145 17.028 6.616e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Anova “assesses the variance that can be attributed to a factor of interest (such as Modality) against the overall variance”, used here for model comparison.</p>
<p>Here, an F statistic is used, because we are comparing variances (vs. the t-statistic, which is used for group differences and regression coefficients).</p>
<p>Report as: “There was a statistically reliable effect of modality (F(4,400) = 17.03, p &lt; 0.0001)”</p>
<p>Res.Df are the degrees of freedom. The more parameters you estimate, the more df you lose. Here, 400 is the number of independent datapoints. The more complex model estimates 4 coefficients more than the null model.</p>
<p>You can also wrap anova() around the model name to automatically compare it to the null model – you don’t actually have to specify the null model.</p>
</div>
<div id="glance" class="section level3">
<h3>glance()</h3>
<pre class="r"><code>glance(senses_mdl)</code></pre>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1     0.146         0.137 0.266      17.0 6.62e-13     5  -35.6  83.3  107.     28.3         400</code></pre>
<p>Since there is only one predictor here, we get the same output as with the anova. If it were more complicated, you would get the statistics for the full model with all predictors compared to a null model. Basically this asks “how well do all predictors together capture variance in the response?” or “assuming the full model and the null model perform equally well (the null hypothesis), how surprising is the amount of sample variance explained by the full model?”(186)</p>
<p>For all pairwise differences, you can use the emmeans package (see Bodo p.186-188 for info and criticism). On the other hand, if only one of the comparison levels is theoretically motivated, you can lump some levels together and thus perform only one test (p.188-200).</p>
</div>
<div id="predict" class="section level3">
<h3>predict()</h3>
<pre class="r"><code>newpreds &lt;- tibble(Modality = sort(unique(senses$Modality)))

sense_preds &lt;- predict(senses_mdl, newpreds, interval = &quot;confidence&quot;) #automatically returns CIs

sense_preds &lt;- cbind(newpreds, sense_preds) #adds the label back in

sense_preds</code></pre>
<pre><code>##   Modality      fit      lwr      upr
## 1    Sight 5.579663 5.542518 5.616808
## 2    Smell 5.471012 5.366477 5.575546
## 3    Sound 5.405193 5.341338 5.469047
## 4    Taste 5.808124 5.731884 5.884364
## 5    Touch 5.534435 5.471052 5.597818</code></pre>
</div>
<div id="plot-means-and-cis" class="section level3">
<h3>Plot means and CIs</h3>
<pre class="r"><code>sense_order &lt;- arrange(sense_preds, fit)$Modality
sense_preds &lt;- mutate(sense_preds, Modality = factor(Modality, levels = sense_order))

ggplot(aes(x=Modality, y=fit), data=sense_preds) +
  geom_point() +
  geom_errorbar(aes(ymin=lwr, ymax=upr)) #formatting suggestions p194</code></pre>
<p><img src="inferential_stats_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="plotting-continuous-predictors" class="section level2">
<h2>Plotting continuous predictors</h2>
<pre class="r"><code>ELP  &lt;- read_csv(&quot;data/ELP_frequency.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   Word = col_character(),
##   Freq = col_double(),
##   RT = col_double()
## )</code></pre>
<pre class="r"><code>ELP &lt;- ELP %&gt;% 
  mutate(Log10Freq = log10(Freq))

ELP_mdl &lt;- lm(RT ~ Log10Freq, ELP)

#generate predictions
newdata &lt;- tibble(Log10Freq = seq(0,5,0.01))
preds &lt;- predict(ELP_mdl, newdata, interval = &quot;confidence&quot;)

preds &lt;- cbind(newdata, preds) #add labels back in

head(preds)</code></pre>
<pre><code>##   Log10Freq      fit      lwr      upr
## 1      0.00 870.9054 780.8520 960.9588
## 2      0.01 870.2026 780.4127 959.9926
## 3      0.02 869.4999 779.9732 959.0266
## 4      0.03 868.7971 779.5334 958.0608
## 5      0.04 868.0943 779.0935 957.0952
## 6      0.05 867.3916 778.6534 956.1298</code></pre>
<pre class="r"><code>ggplot(aes(x=Log10Freq, y=fit), data=preds) +
  geom_ribbon(aes(ymin=lwr, ymax=upr), fill=&quot;grey&quot;, alpha=0.5) +
  geom_line() +
  geom_text(aes(y=RT, label=Word), data=ELP) +
  theme_minimal()</code></pre>
<p><img src="inferential_stats_files/figure-html/unnamed-chunk-10-1.png" width="672" /> The grey region shows the model lines you would be expected to get 95% of the time when sampling from the same population.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
